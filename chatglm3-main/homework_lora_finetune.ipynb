{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76baf3c4-f38b-481a-8c5a-107416f0a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvertiseGen.tar.gz  homework_lora_finetune.ipynb  README_en.md\n",
      "configs\t\t     inference_hf.py\t\t   README.md\n",
      "finetune_hf.py\t     lora_finetune.ipynb\t   requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bde2fde-a19d-421a-928c-597e829ba6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip AdvertiseGen.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90b784a-dbe0-41ad-8dba-f609536f0bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvertiseGen/\n",
      "AdvertiseGen/train.json\n",
      "AdvertiseGen/dev.json\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf AdvertiseGen.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebfd50f-0dc5-4a3c-93e2-3709bc4d97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('AdvertiseGen', 'AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7442aca-9067-438b-bb6f-4a1e005f8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c66d04e-58f7-498e-b64f-7362d2d7fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install gcc_linux-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c8a081-4f4f-43e7-9a6c-2b92f8ae454f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /data/minconda3/envs/llm/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: jieba>=0.42.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.42.1)\n",
      "Requirement already satisfied: ruamel_yaml>=0.18.6 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.18.6)\n",
      "Requirement already satisfied: rouge_chinese>=1.0.3 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
      "Collecting datasets>=2.17.1 (from -r requirements.txt (line 5))\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/9f/8a/3922b6d4a8fb40db454abd5d66b28215b047563564f044de693643d5d07f/datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft>=0.10.0 (from -r requirements.txt (line 6))\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/b4/5d/758c00ba637bc850f35fff7fad442c470ac3d606fe586d881b0bed7ef5a5/peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "Collecting deepspeed==0.13.1 (from -r requirements.txt (line 8))\n",
      "  Using cached deepspeed-0.13.1-py3-none-any.whl\n",
      "Collecting mpi4py>=3.1.5 (from -r requirements.txt (line 9))\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/b3/17/1d146e0127b66f1945251f130afac430985d2f9d75a3c0330355f21d876a/mpi4py-3.1.6.tar.gz (2.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hjson (from deepspeed==0.13.1->-r requirements.txt (line 8))\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m800.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ninja (from deepspeed==0.13.1->-r requirements.txt (line 8))\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/6d/92/8d7aebd4430ab5ff65df2bfee6d5745f95c004284db2d8ca76dcbfd9de47/ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Requirement already satisfied: numpy in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (23.2)\n",
      "Requirement already satisfied: psutil in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (5.9.0)\n",
      "Collecting py-cpuinfo (from deepspeed==0.13.1->-r requirements.txt (line 8))\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pydantic in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (2.6.4)\n",
      "Collecting pynvml (from deepspeed==0.13.1->-r requirements.txt (line 8))\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/5b/9c/adb8070059caaa15d5a572b66bccd95900d8c1b9fa54d6ecea6ae97448d1/pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: torch in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: tqdm in /data/minconda3/envs/llm/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (4.65.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from ruamel_yaml>=0.18.6->-r requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: six in /data/minconda3/envs/llm/lib/python3.11/site-packages (from rouge_chinese>=1.0.3->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: filelock in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /data/minconda3/envs/llm/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.22.0rc0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: transformers in /data/minconda3/envs/llm/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (4.37.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.26.1)\n",
      "Requirement already satisfied: safetensors in /data/minconda3/envs/llm/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets>=2.17.1->-r requirements.txt (line 5)) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (1.12)\n",
      "Requirement already satisfied: networkx in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.4.99)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.16.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from jinja2->torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/minconda3/envs/llm/lib/python3.11/site-packages (from sympy->torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (1.3.0)\n",
      "Building wheels for collected packages: mpi4py\n",
      "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for mpi4py \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[148 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_src\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.py -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.py -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.py -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.py -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_base.py -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.py -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.py -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.py -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/dl.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/py.typed -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pxd -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/libmpi.pxd -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pxd -> build/lib.linux-x86_64-cpython-311/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py/include\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI.h -> build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI_api.h -> build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.h -> build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.i -> build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi.pxi -> build/lib.linux-x86_64-cpython-311/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.pyi -> build/lib.linux-x86_64-cpython-311/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m running build_clib\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for library 'lmpe' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -llmpe -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -llmpe: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'mpe' dylib library\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-311/src/lib-pmpi\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c src/lib-pmpi/mpe.c -o build/temp.linux-x86_64-cpython-311/src/lib-pmpi/mpe.o\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/mpi4py/lib-pmpi\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -shared -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,--no-as-needed build/temp.linux-x86_64-cpython-311/src/lib-pmpi/mpe.o -o build/lib.linux-x86_64-cpython-311/mpi4py/lib-pmpi/libmpe.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt-mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt-mpi: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt.mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt.mpi: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c src/lib-pmpi/vt.c -o build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -shared -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,--no-as-needed build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt.o -o build/lib.linux-x86_64-cpython-311/mpi4py/lib-pmpi/libvt.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt-mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt-mpi: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt.mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt.mpi: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-mpi' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c src/lib-pmpi/vt-mpi.c -o build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt-mpi.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -shared -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,--no-as-needed build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt-mpi.o -o build/lib.linux-x86_64-cpython-311/mpi4py/lib-pmpi/libvt-mpi.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-hyb' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt-hyb -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt-hyb: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.ompi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -lvt.ompi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /data/minconda3/envs/llm/compiler_compat/ld: cannot find -lvt.ompi: No such file or directory\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-hyb' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -c src/lib-pmpi/vt-hyb.c -o build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt-hyb.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -shared -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,--no-as-needed build/temp.linux-x86_64-cpython-311/src/lib-pmpi/vt-hyb.o -o build/lib.linux-x86_64-cpython-311/mpi4py/lib-pmpi/libvt-hyb.so\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for dlopen() availability ...\n",
      "  \u001b[31m   \u001b[0m checking for header 'dlfcn.h' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -I/data/minconda3/envs/llm/include/python3.11 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m checking for library 'dl' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -I/data/minconda3/envs/llm/include/python3.11 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -Lbuild/temp.linux-x86_64-cpython-311 -ldl -o _configtest\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o _configtest\n",
      "  \u001b[31m   \u001b[0m checking for function 'dlopen' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -I/data/minconda3/envs/llm/include/python3.11 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat _configtest.o -Lbuild/temp.linux-x86_64-cpython-311 -ldl -o _configtest\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o _configtest\n",
      "  \u001b[31m   \u001b[0m building 'mpi4py.dl' extension\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -DHAVE_DLFCN_H=1 -DHAVE_DLOPEN=1 -I/data/minconda3/envs/llm/include/python3.11 -c src/dynload.c -o build/temp.linux-x86_64-cpython-311/src/dynload.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -shared -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib -Wl,-rpath,/data/minconda3/envs/llm/lib -Wl,-rpath-link,/data/minconda3/envs/llm/lib -L/data/minconda3/envs/llm/lib build/temp.linux-x86_64-cpython-311/src/dynload.o -Lbuild/temp.linux-x86_64-cpython-311 -ldl -o build/lib.linux-x86_64-cpython-311/mpi4py/dl.cpython-311-x86_64-linux-gnu.so\n",
      "  \u001b[31m   \u001b[0m checking for MPI compile and link ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /data/minconda3/envs/llm/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -O2 -isystem /data/minconda3/envs/llm/include -fPIC -I/data/minconda3/envs/llm/include/python3.11 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m _configtest.c:2:10: fatal error: mpi.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     2 | #include <mpi.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m error: Cannot compile MPI programs. Check your configuration!!!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for mpi4py\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build mpi4py\n",
      "\u001b[31mERROR: Could not build wheels for mpi4py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc403b3-b7f5-4641-b7b9-54f6acd9b94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /data/minconda3/envs/llm/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting rouge_chinese\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/03/0f/394cf877be7b903881020ef7217f7dc644dad158d52a9353fcab22e3464d/rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: six in /data/minconda3/envs/llm/lib/python3.11/site-packages (from rouge_chinese) (1.16.0)\n",
      "Installing collected packages: rouge_chinese\n",
      "Successfully installed rouge_chinese-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af96bd6-61bf-4d6e-9744-0b53ece9e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-14 15:17:11.607770: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-14 15:17:11.649118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 15:17:12.282106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:27<00:00,  3.90s/it]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 300\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.8973, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}         \n",
      "{'loss': 4.7508, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.0}          \n",
      "  7%|██▊                                       | 20/300 [00:23<04:12,  1.11it/s]Saving model checkpoint to ./output/tmp-checkpoint-20\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.6426, 'learning_rate': 4.5e-05, 'epoch': 0.0}                        \n",
      "{'loss': 4.2031, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.0}         \n",
      " 13%|█████▌                                    | 40/300 [00:40<03:21,  1.29it/s]Saving model checkpoint to ./output/tmp-checkpoint-40\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.083, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.0}           \n",
      " 17%|███████                                   | 50/300 [00:50<03:53,  1.07it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:21<00:21, 10.62s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:41<00:14, 14.83s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:58<00:00, 15.43s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.472 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 26.313562, 'eval_rouge-2': 4.575146, 'eval_rouge-l': 15.866444000000001, 'eval_bleu-4': 0.015990818896408677, 'eval_runtime': 82.217, 'eval_samples_per_second': 0.608, 'eval_steps_per_second': 0.049, 'epoch': 0.0}\n",
      " 17%|███████                                   | 50/300 [02:12<03:53,  1.07it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:59<00:00, 15.43s/it]\u001b[A\n",
      "{'loss': 4.0455, 'learning_rate': 4e-05, 'epoch': 0.0}                          \u001b[A\n",
      " 20%|████████▍                                 | 60/300 [02:21<07:34,  1.89s/it]Saving model checkpoint to ./output/tmp-checkpoint-60\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.9742, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.0}         \n",
      "{'loss': 3.952, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.0}          \n",
      " 27%|███████████▏                              | 80/300 [02:39<03:28,  1.06it/s]Saving model checkpoint to ./output/tmp-checkpoint-80\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.7701, 'learning_rate': 3.5e-05, 'epoch': 0.0}                        \n",
      "{'loss': 3.7432, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.0}         \n",
      " 33%|█████████████▋                           | 100/300 [02:57<02:50,  1.18it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.94s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 28.7241, 'eval_rouge-2': 5.393444, 'eval_rouge-l': 23.172589999999996, 'eval_bleu-4': 0.02699863261353248, 'eval_runtime': 27.3988, 'eval_samples_per_second': 1.825, 'eval_steps_per_second': 0.146, 'epoch': 0.0}\n",
      " 33%|█████████████▋                           | 100/300 [03:25<02:50,  1.18it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  7.45s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-100\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.6605, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.0}         \n",
      "{'loss': 3.6643, 'learning_rate': 3e-05, 'epoch': 0.0}                          \n",
      " 40%|████████████████▍                        | 120/300 [03:44<02:43,  1.10it/s]Saving model checkpoint to ./output/tmp-checkpoint-120\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.7293, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.0}         \n",
      "{'loss': 3.7223, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.0}         \n",
      " 47%|███████████████████▏                     | 140/300 [04:01<02:14,  1.19it/s]Saving model checkpoint to ./output/tmp-checkpoint-140\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.7209, 'learning_rate': 2.5e-05, 'epoch': 0.01}                       \n",
      " 50%|████████████████████▌                    | 150/300 [04:11<02:26,  1.02it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:21<00:21, 10.63s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:25<00:07,  7.82s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 29.268732, 'eval_rouge-2': 5.56663, 'eval_rouge-l': 21.630074, 'eval_bleu-4': 0.0260060305966515, 'eval_runtime': 62.7823, 'eval_samples_per_second': 0.796, 'eval_steps_per_second': 0.064, 'epoch': 0.01}\n",
      " 50%|████████████████████▌                    | 150/300 [05:13<02:26,  1.02it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:41<00:00, 10.81s/it]\u001b[A\n",
      "{'loss': 3.6625, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.01}        \u001b[A\n",
      " 53%|█████████████████████▊                   | 160/300 [05:22<03:58,  1.70s/it]Saving model checkpoint to ./output/tmp-checkpoint-160\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.6148, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.01}        \n",
      "{'loss': 3.6814, 'learning_rate': 2e-05, 'epoch': 0.01}                         \n",
      " 60%|████████████████████████▌                | 180/300 [05:41<01:52,  1.06it/s]Saving model checkpoint to ./output/tmp-checkpoint-180\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.6209, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.01}        \n",
      "{'loss': 3.6811, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.01}        \n",
      " 67%|███████████████████████████▎             | 200/300 [05:59<01:29,  1.12it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:21<00:21, 10.66s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:42<00:14, 14.87s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 28.812074000000003, 'eval_rouge-2': 5.850634, 'eval_rouge-l': 22.150926000000005, 'eval_bleu-4': 0.027397235621707327, 'eval_runtime': 79.6057, 'eval_samples_per_second': 0.628, 'eval_steps_per_second': 0.05, 'epoch': 0.01}\n",
      " 67%|███████████████████████████▎             | 200/300 [07:19<01:29,  1.12it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:58<00:00, 15.24s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-200\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.6191, 'learning_rate': 1.5e-05, 'epoch': 0.01}                       \n",
      "{'loss': 3.5992, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.01}        \n",
      " 73%|██████████████████████████████           | 220/300 [07:38<01:19,  1.00it/s]Saving model checkpoint to ./output/tmp-checkpoint-220\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.5801, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.01}        \n",
      "{'loss': 3.5541, 'learning_rate': 1e-05, 'epoch': 0.01}                         \n",
      " 80%|████████████████████████████████▊        | 240/300 [07:56<00:55,  1.07it/s]Saving model checkpoint to ./output/tmp-checkpoint-240\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.618, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.01}          \n",
      " 83%|██████████████████████████████████▏      | 250/300 [08:06<00:43,  1.15it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.83s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:09,  9.71s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 29.102763999999997, 'eval_rouge-2': 5.692024, 'eval_rouge-l': 22.534388, 'eval_bleu-4': 0.026851109503827783, 'eval_runtime': 49.0578, 'eval_samples_per_second': 1.019, 'eval_steps_per_second': 0.082, 'epoch': 0.01}\n",
      " 83%|██████████████████████████████████▏      | 250/300 [08:55<00:43,  1.15it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:27<00:00,  7.21s/it]\u001b[A\n",
      "{'loss': 3.6252, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \u001b[A\n",
      " 87%|███████████████████████████████████▌     | 260/300 [09:04<01:00,  1.50s/it]Saving model checkpoint to ./output/tmp-checkpoint-260\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.6051, 'learning_rate': 5e-06, 'epoch': 0.01}                         \n",
      "{'loss': 3.7139, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}        \n",
      " 93%|██████████████████████████████████████▎  | 280/300 [09:21<00:16,  1.19it/s]Saving model checkpoint to ./output/tmp-checkpoint-280\n",
      "/data/minconda3/envs/llm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.5244, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.01}        \n",
      "{'loss': 3.5783, 'learning_rate': 0.0, 'epoch': 0.01}                           \n",
      "100%|█████████████████████████████████████████| 300/300 [09:39<00:00,  1.18it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.52s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:09,  9.53s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 29.572116, 'eval_rouge-2': 5.76286, 'eval_rouge-l': 22.87342, 'eval_bleu-4': 0.028920912444082635, 'eval_runtime': 47.7482, 'eval_samples_per_second': 1.047, 'eval_steps_per_second': 0.084, 'epoch': 0.01}\n",
      "100%|█████████████████████████████████████████| 300/300 [10:27<00:00,  1.18it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:26<00:00,  6.82s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-300\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 627.6387, 'train_samples_per_second': 1.912, 'train_steps_per_second': 0.478, 'train_loss': 3.8279036458333335, 'epoch': 0.01}\n",
      "100%|█████████████████████████████████████████| 300/300 [10:27<00:00,  2.09s/it]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [20:46<00:00, 18.60s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python finetune_hf.py  AdvertiseGen_fix  /data/glm/ChatGLM-6B-main/THUDM/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b061afe-3e46-45a9-b278-4709976152c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-100\tcheckpoint-180\tcheckpoint-240\tcheckpoint-40\n",
      "checkpoint-120\tcheckpoint-20\tcheckpoint-260\tcheckpoint-60\n",
      "checkpoint-140\tcheckpoint-200\tcheckpoint-280\tcheckpoint-80\n",
      "checkpoint-160\tcheckpoint-220\tcheckpoint-300\truns\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5342c2f5-7c7d-444c-a0ac-efb7c822431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:36<00:00,  5.17s/it]\n",
      "2024-05-14 15:55:15.705544: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-14 15:55:16.480593: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 15:55:17.892474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "百褶连衣裙的款式，加上网纱拼接，让整件连衣裙显得更有层次感。下摆的百褶设计，加上侧边拉链的装饰，显得十分精致。侧边抽褶的装饰，让裙身显得更加修身，加上拼接的木耳边，让整体显得更加优雅。整体的设计，加上网纱的拼接，让连衣裙显得更加性感。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python inference_hf.py output/checkpoint-300/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
